{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string1 = \"Hi all -- \\n\\n Here is today's demo group schedule! It's a little different than last week. \\\n",
    "You'll each spend 2 hrs in a room watching demos as a group. You'll spend the other 2 hours out at the desks (\\\n",
    "fun fact: this room is called Ocean; now you know) in small groups of 4-5, where you can deep \\\n",
    "dive each other's demos / projects and give feedback. Let me know if anything is weird on the schedule -- your \\\n",
    "name should be on there once during each time block: 2 hrs in a large group, and 2 hrs in a small group.\\\n",
    "\\n\\n I'll post a copy of the schedule on the doors to Boa and Party as well! \\\n",
    "See you then. Remember to eat lunch. \\n\\n Katie\"\n",
    "\n",
    "test_string2 = \"Hi Fellows, \\n\\n The start of the session is two weeks away! Things are about to get real. \\n\\n \\\n",
    "We created a handbook that previews the learning environment you'll experience (and help create!) as an Insight Fellow. \\\n",
    "It includes advice from members of our alumni community that we encourage you to review as you prepare for the first week of the program. \\n\\n \\\n",
    "We're excited to meet you all in person! \\n\\n Thanks, \\n Katie\"\n",
    "\n",
    "test_emails = [test_string1, test_string2]\n",
    "\n",
    "senders_list = ['Katie Hawkes']\n",
    "receiver_list = [['Ben Regner', 'April Swagman', 'DS-SV'], ['DS-SV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = []\n",
    "total_msg_lens = []\n",
    "periods, commas = [], []\n",
    "ex_marks, q_marks = [], []\n",
    "word_tokens = []\n",
    "pos = []\n",
    "for email in test_emails:\n",
    "    caps.append(sum(1 for s in email if s.isupper()))\n",
    "    total_msg_lens.append(len(email))\n",
    "    periods.append(sum(1 for s in email if s == '.'))\n",
    "    commas.append(sum(1 for s in email if s == ','))\n",
    "    ex_marks.append(sum(1 for s in email if s == '!'))\n",
    "    q_marks.append(sum(1 for s in email if s == '?'))\n",
    "    #email = email.lower()\n",
    "    pos.append(nlp(email))\n",
    "    word_tokens.append(word_tokenize(email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "word_counts = []\n",
    "for i in range(len(word_tokens)):\n",
    "    words = [w for w in word_tokens[i] if not w in punct]\n",
    "    word_counts.append(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = pd.DataFrame(\n",
    "    {\n",
    "        'caps':caps,\n",
    "        'msg_len':total_msg_lens,\n",
    "        'periods':periods,\n",
    "        'commas':commas,\n",
    "        'ex_marks':ex_marks,\n",
    "        'q_marks':q_marks,\n",
    "        'word_count':word_counts\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add POS information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "pos_counts = []\n",
    "for doc in pos:\n",
    "    d = defaultdict(int)\n",
    "    for word in doc:\n",
    "        d[word.pos_] +=1\n",
    "    pos_counts.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_counts = pd.DataFrame(pos_counts)\n",
    "df_pos_counts.columns = df_pos_counts.columns.str.lower()\n",
    "df_pos_counts.replace(np.nan, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj</th>\n",
       "      <th>adp</th>\n",
       "      <th>adv</th>\n",
       "      <th>cconj</th>\n",
       "      <th>det</th>\n",
       "      <th>intj</th>\n",
       "      <th>noun</th>\n",
       "      <th>num</th>\n",
       "      <th>part</th>\n",
       "      <th>pron</th>\n",
       "      <th>propn</th>\n",
       "      <th>punct</th>\n",
       "      <th>space</th>\n",
       "      <th>sym</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adj  adp  adv  cconj  det  intj  noun  num  part  pron  propn  punct  \\\n",
       "0   11   16    8      3   15     1    30    6     3     8      4     17   \n",
       "1    5   10    1      1    8     1    15    1     3     8      4     10   \n",
       "\n",
       "   space  sym  verb  \n",
       "0      3  2.0    25  \n",
       "1      5  0.0    15  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos_counts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = pd.concat([text_features, df_pos_counts], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of sentences and average length of sentence in message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentences = []\n",
    "sentence_len_mean = []\n",
    "for email in test_emails:\n",
    "    tokens = sent_tokenize(email)\n",
    "    num_sentences.append(len(tokens))\n",
    "    len_sentence = []\n",
    "    for token in tokens:\n",
    "        s = ''.join(ch for ch in token if ch not in string.punctuation)\n",
    "        s = s.strip()\n",
    "        len_sentence.append(len(s.split(' ')))\n",
    "    if len_sentence:\n",
    "        sentence_len_mean.append(np.mean(len_sentence))\n",
    "    else:\n",
    "        sentence_len_mean.append(0)\n",
    "\n",
    "text_features['num_sentences'] = num_sentences\n",
    "text_features['len_sentence_mean'] = sentence_len_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get out how many recipients the email has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_recipients = []\n",
    "for receiver in receiver_list:\n",
    "    num_recipients.append(len(receiver))\n",
    "    \n",
    "text_features['num_recipients'] = num_recipients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender of senders and recipients (if multiple recipients, put 'Group' as gender because any gender effects will likely be washed out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gender_guesser.detector as gender\n",
    "d = gender.Detector(case_sensitive = False)\n",
    "\n",
    "send_gender = []\n",
    "for sender in senders_list:\n",
    "    \n",
    "    #name structure is 'First Last'\n",
    "    send_name = sender.split(' ', 1)[0]\n",
    "    send_gender.append(d.get_gender(send_name))\n",
    "\n",
    "receive_gender = []\n",
    "for receiver in receiver_list:\n",
    "    if len(receiver) > 1:\n",
    "        receive_gender.append('group')\n",
    "    \n",
    "    else:\n",
    "        gender = d.get_gender(receiver[0])\n",
    "        receive_gender.append(gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "sentiments_list = []\n",
    "for email in test_emails:\n",
    "    sentences = sent_tokenize(email)\n",
    "    \n",
    "    sentence_sentiments = []\n",
    "    for sentence in sentences:\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "        sentence_sentiments.append(vs)\n",
    "    \n",
    "    msg_sentiments = {}\n",
    "    for k in vs.keys():\n",
    "        if sentence_sentiments:\n",
    "            mean = sum(d[k] for d in sentence_sentiments) / len(sentence_sentiments)\n",
    "            msg_sentiments[k] = mean\n",
    "        else:\n",
    "            msg_sentiments[k] = np.nan\n",
    "    \n",
    "    sentiments_list.append(msg_sentiments)\n",
    "\n",
    "sentiments = pd.DataFrame(sentiments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caps</th>\n",
       "      <th>commas</th>\n",
       "      <th>ex_marks</th>\n",
       "      <th>msg_len</th>\n",
       "      <th>periods</th>\n",
       "      <th>q_marks</th>\n",
       "      <th>word_count</th>\n",
       "      <th>adj</th>\n",
       "      <th>adp</th>\n",
       "      <th>adv</th>\n",
       "      <th>cconj</th>\n",
       "      <th>det</th>\n",
       "      <th>intj</th>\n",
       "      <th>noun</th>\n",
       "      <th>num</th>\n",
       "      <th>part</th>\n",
       "      <th>pron</th>\n",
       "      <th>propn</th>\n",
       "      <th>punct</th>\n",
       "      <th>space</th>\n",
       "      <th>sym</th>\n",
       "      <th>verb</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>len_sentence_mean</th>\n",
       "      <th>num_recipients</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>629</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>14.111111</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>0.953556</td>\n",
       "      <td>0.031222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>412</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>10.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>0.280386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792143</td>\n",
       "      <td>0.207857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   caps  commas  ex_marks  msg_len  periods  q_marks  word_count  adj  adp  \\\n",
       "0    13       2         2      629        6        0         131   11   16   \n",
       "1    11       2         3      412        3        0          72    5   10   \n",
       "\n",
       "   adv  cconj  det  intj  noun  num  part  pron  propn  punct  space  sym  \\\n",
       "0    8      3   15     1    30    6     3     8      4     17      3  2.0   \n",
       "1    1      1    8     1    15    1     3     8      4     10      5  0.0   \n",
       "\n",
       "   verb  num_sentences  len_sentence_mean  num_recipients  compound       neg  \\\n",
       "0    25              9          14.111111               3  0.007389  0.015222   \n",
       "1    15              7          10.285714               1  0.280386  0.000000   \n",
       "\n",
       "        neu       pos  \n",
       "0  0.953556  0.031222  \n",
       "1  0.792143  0.207857  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features = pd.concat([text_features, sentiments], axis = 1)\n",
    "\n",
    "text_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 29)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_vectors = pickle.load(open('12-cluster_vectors.p', 'rb'))\n",
    "new_vectors = text_features.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 30 while Y.shape[1] == 29",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-d41b0bbf995d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcluster_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insight/project_env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insight/project_env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    121\u001b[0m         raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n\u001b[1;32m    122\u001b[0m                          \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n\u001b[0;32m--> 123\u001b[0;31m                              X.shape[1], Y.shape[1]))\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 30 while Y.shape[1] == 29"
     ]
    }
   ],
   "source": [
    "cluster_assignments = []\n",
    "for new in new_vectors:\n",
    "    best_score = 0\n",
    "    cluster_num = None\n",
    "    for cluster, vector in cluster_vectors.items():\n",
    "        score = cosine_similarity(vector.reshape(1, -1), new.reshape(1, -1))[0][0]\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            cluster_num = cluster\n",
    "    cluster_assignments.append((cluster_num, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = {\n",
    "    -1:'Work may be a little stressful',\n",
    "    0:'Direct and to the point',\n",
    "    1:'Business as usual',\n",
    "    2:'Casual and personal',\n",
    "    3:'Company announcements',\n",
    "    4:'Meetings and interviews'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
