{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining the social web\n",
    "\n",
    "Code adapted from [here](https://www.safaribooksonline.com/library/view/mining-the-social/9781449368180/ch06.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "import os\n",
    "import envoy \n",
    "import mailbox\n",
    "import email\n",
    "import quopri\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "import re\n",
    "from time import asctime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"http://www.cs.cmu.edu/~enron/enron_mail_20110402.tgz\"\n",
    "DOWNLOAD_DIR = \"/Users/yuwenwu/insight/cultivate/data/external/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, download_dir):    \n",
    "    file_name = url.split('/')[-1]\n",
    "    u = urlopen(url)\n",
    "    f = open(os.path.join(download_dir, file_name), 'wb')\n",
    "    meta = u.info()\n",
    "    file_size = int(meta.get_all(\"Content-Length\")[0])\n",
    "    #print(\"Downloading: {} Bytes: {}\".format(file_name, file_size))\n",
    "\n",
    "    file_size_dl = 0\n",
    "    block_sz = 8192\n",
    "    last_update = time.time()\n",
    "    while True:\n",
    "        buffer = u.read(block_sz)\n",
    "        if not buffer:\n",
    "            break\n",
    "\n",
    "        file_size_dl += len(buffer)\n",
    "        f.write(buffer)\n",
    "        download_status = r\"%10d MB  [%3.2f%%]\" % (file_size_dl / 1000000.0, file_size_dl * 100.0 / file_size)\n",
    "        download_status = download_status + chr(8)*(len(download_status)+1)\n",
    "        if time.time() - last_update > 5:\n",
    "            #print(download_status),\n",
    "            sys.stdout.flush()\n",
    "            last_update = time.time()\n",
    "    f.close()\n",
    "    return f.name\n",
    "\n",
    "# Extracts a gzipped tarfile. e.g. \"$ tar xzf filename.tgz\"\n",
    "\n",
    "def tar_xzf(f):\n",
    "    # Call out to the shell for a faster decompression.\n",
    "    # This will still take a while because Vagrant synchronizes\n",
    "    # thousands of files that are extracted to the host machine\n",
    "    r = envoy.run(\"tar xzf {} -C {}\".format(f, DOWNLOAD_DIR))\n",
    "    #print(r.std_out)\n",
    "    #print(r.std_err)\n",
    "\n",
    "f = download(URL, DOWNLOAD_DIR)\n",
    "_ = tar_xzf(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert raw email data to mbox format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAILDIR = DOWNLOAD_DIR + 'enron_mail_20110402/maildir' \n",
    "\n",
    "# Where to write the converted mbox\n",
    "MBOX = DOWNLOAD_DIR + '/enron.mbox'\n",
    "\n",
    "# Create a file handle that we'll be writing into...\n",
    "mbox = open(MBOX, 'w')\n",
    "\n",
    "# Walk the directories and process any folder named 'inbox'\n",
    "\n",
    "for (root, dirs, file_names) in os.walk(MAILDIR):\n",
    "\n",
    "    if root.split(os.sep)[-1].lower() not in ['_sent_mail', 'discussion_threads', 'inbox', 'sent_items']:\n",
    "        continue\n",
    "\n",
    "    # Process each message in 'inbox'\n",
    "\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(root, file_name)\n",
    "        message_text = open(file_path, 'wb')\n",
    "\n",
    "        # Compute fields for the From_ line in a traditional mbox message\n",
    "\n",
    "        _from = re.search(r\"From: ([^\\n]+)\", message_text).groups()[0]\n",
    "        _date = re.search(r\"Date: ([^\\n]+)\", message_text).groups()[0]\n",
    "\n",
    "        # Convert _date to the asctime representation for the From_ line\n",
    "\n",
    "        _date = asctime(parse(_date).timetuple())\n",
    "\n",
    "        msg = email.message_from_string(message_text)\n",
    "        msg.set_unixfrom('From %s %s' % (_from, _date))\n",
    "\n",
    "        _ = mbox.write(msg.as_string(unixfrom=True) + \"\\n\\n\");\n",
    "    \n",
    "mbox.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert mbox to json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(msg):\n",
    "\n",
    "    # Decode message from \"quoted printable\" format\n",
    "    msg = quopri.decodestring(msg)\n",
    "        \n",
    "    # Strip out HTML tags, if any are present.\n",
    "    # Bail on unknown encodings if errors happen in BeautifulSoup.\n",
    "    try:\n",
    "        soup = BeautifulSoup(msg, 'lxml')\n",
    "    except:\n",
    "        return ''\n",
    "    return ''.join(soup.findAll(text=True))\n",
    "\n",
    "# There's a lot of data to process, and the Pythonic way to do it is with a \n",
    "# generator. See http://wiki.python.org/moin/Generators.\n",
    "# Using a generator requires a trivial encoder to be passed to json for object \n",
    "# serialization.\n",
    "\n",
    "class Encoder(json.JSONEncoder):\n",
    "    def default(self, o): return  list(o)\n",
    "        \n",
    "def jsonifyMessage(msg):\n",
    "    json_msg = {'parts': []}\n",
    "    for (k, v) in msg.items():\n",
    "        json_msg[k] = v\n",
    "\n",
    "    # The To, Cc, and Bcc fields, if present, could have multiple items.\n",
    "    # Note that not all of these fields are necessarily defined.\n",
    "\n",
    "    for k in ['To', 'Cc', 'Bcc']:\n",
    "        if not json_msg.get(k):\n",
    "            continue\n",
    "        json_msg[k] = json_msg[k].replace('\\n', '').replace('\\t', '').replace('\\r', '')\\\n",
    "                                 .replace(' ', '').split(',')\n",
    "\n",
    "    for part in msg.walk():\n",
    "        json_part = {}\n",
    "        if part.get_content_maintype() == 'multipart':\n",
    "            continue\n",
    "            \n",
    "        json_part['contentType'] = part.get_content_type()\n",
    "        content = part.get_payload(decode=False)\n",
    "        json_part['content'] = clean_content(content)\n",
    "           \n",
    "        json_msg['parts'].append(json_part)\n",
    "        \n",
    "    if 'Date' not in json_msg:\n",
    "        return\n",
    "    else:\n",
    "        date_time = pd.to_datetime(json_msg['Date'])\n",
    "        json_msg['Date'] = str(date_time)\n",
    "\n",
    "    return json_msg\n",
    "\n",
    "mbox = mailbox.mbox('enron.mbox')\n",
    "OUT_FILE = DOWNLOAD_DIR + '/enron.mbox.json'\n",
    "\n",
    "all_jsons = []\n",
    "for message in mbox:\n",
    "    json_msg = jsonifyMessage(message)\n",
    "    if json_msg != None:\n",
    "        all_jsons.append(json_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(OUT_FILE, 'w')\n",
    "_ = f.write(json.dumps(all_jsons, cls=Encoder));\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
